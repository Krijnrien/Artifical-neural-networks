{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial (classic) neural networks - theory\n",
    "\n",
    "Neural networks are often compared to brains, simulating dense fully interconnected layers of neurons to learn how to recognize patterns. The practicality behind neural networks is that it is not taught explicitly but rather learns by itself, from given examples.\n",
    "\n",
    "Typical standard neural network has a range from a few dozen to thousands of artificial neurons, generally called units or nodes, arranged in a series of layers. Nodes have values ranging from `0.0` to `1.0`, where `0` represents fully inactive and `1` represents fully active, with all (infinite) possible values inbetween. Each node in each layer is connected to its neighbours layer's neurons, as depicted in below's image. The lines connected from one node to another are called `weights`, determining whether the strength of the activated node should activate the connected neuron. \n",
    "\n",
    "The left most layer in neural networks is called the input layer. All the nodes in the input layer are the variables you wish to `feed` to the neural network. The right most layer in a neural network is called the output layer. The nodes in the output layer represent the values, the amount of output values equalling the amount of output nodes, one wishes to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layers\n",
    "\n",
    "Layers between the input and output layer are called hidden layers, these are responsible for detecting pattersn which make neural networks purposeful. Neural networks (hidden layers) can detect patterns by activating nodes only if the weighted treshhold of multiple other nodes from a previous connected layer reached an activation treshold; this happens in hidden layers, these are all the layers inbetween the input and output layers.\n",
    "![simple-nn](sources/simple-nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the following hidden layer node below. The hidden layer node is connect to 3 other nodes from the previous layer. Said hidden neuron has a activation treshold, meaning that it only `activates` when the 3 other connected nodes have high enough values. \n",
    "![activation-node](sources/activation-node.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algebraic mathematics behind above illustrated activation function is depicted below; where `x` equials the input nodes, `w` equals the `weights`, and `âˆ‘j` the weighted sum. For simlicity reasons the mathematically described node below only has a binary output of either 0 or 1, no possible inbetween numbers as mentioned earlier.\n",
    "![activation-node-mathematics](sources/activation-math.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more illustrative version of above's equation would be the following.\n",
    "\n",
    "![nn-equation](sources/nn-math-function.j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten digits example\n",
    "How would a computer recognize handwritten digits? One could write a computer vision (CV) algorithm which detects exact shapes, which inheritently describes the problem: exact shapes. Handwriting is pretty much unique for each person, everybody writes each digit slightly different. it's trivial to write a CV implementation trying to take into account every handwritten form of each digit. Instead we can a neural network which will do the same as a CV implementation: detecting shapes. However a neural network can learn by itself, given enough data. There is no need for an engineer to endlessly program each possible shape for each digit into an CV algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a dataset containing 70,000 labelled images of handwritten digits.\n",
    "![digits](sources/digits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from earlier, the input layer consists of all variables one wants to feed the neural network. In this case we want to classify an image as a digit; hence all pixels of said image become input variables which in turn is a node in the input layer. Each image in the MNIST dataset are 28 by 28 pixels, 28x28 equals 784 pixels. The input layer will have 784 nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![math](sources/overview-mnist-nn.png =100x20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![math](sources/digits-nn-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to recognize patterns the neural network needs hidden layers, which will detect shapes of the handwritten digit. The amount of required hidden layers and neurons in said layer is more or less open for trial and error. Basically each neuron in a hidden layer detects a specific shape, a pattern. Adding extra hidden layers would result in the detection of larger shapes, for example the vertical curved line or o-shape in the digit 9. Typical shapes are illustrated below as example.\n",
    "![low-level-shapes](sources/low-shapes-patterns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural network to classify handwritten digits - practical\n",
    "\n",
    "When reading in the data, the images are labeled using one-hot-encoding which uses a vector of binary values to represent numeric or categorical values. Requiring only 10 labels for the digits 0-9, one for each digit, as any higher number is just a combination of digits. E.g. the digit 3 is represented using the vector `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`. As the value at index 3 is stored as 1, the vector therefore represents the digit 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all libraries!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.cmap'] = 'Greys'\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "print(\"Imported all libraries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST dataset\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MNIST dataset\")\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2793a969ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = mnist.train.images[0]\n",
    "reshaped = image.reshape((28, 28))\n",
    "label = mnist.train.labels[0]\n",
    "\n",
    "print(label)\n",
    "plt.imshow(reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the one-hot-encoding mentioned earlier. The vector 7th index is marked as 1, so the image should be a 7 and as the image indicates, that seems about right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 28x28 image is flattened into a 1D vector that is 28x28=784 pixels in size. Each of the image's 784 pixels is stored as a value from 0 to 255. It specifies the pixel's grayscale, because the images are shown only in black and white. So 255 is a black pixel and 0 is a white pixel with the various shades of gray inbetween."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![digit-matrix](sources/digit-matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow placeholders are to feed the actual training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow variables and nn activation functions are trainable variables such as weights biases for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.zeros([784, 100]))\n",
    "b1 = tf.Variable(tf.zeros([100]))\n",
    "h1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.zeros([100, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(h1, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring model accuracy\n",
    "\n",
    "Generally machine learning models accuracy is measured in Mean Squared Error (MSE). However, for Neural Networks, it's generally more accurate to use `Cross-Entropy Error` (CSE) to measure accuracy. Suppose a neural network is classifying data and the outcome is a score from 0-1 how sure it is of each possible output label. To measure accuracy we consider  3 seperate inputs for the NN to predict; 2 were predicted correctly, and 1 was wrong. MSE will measure this as a 1/3 classification error, 2/3 correct which results in an 0.67 accuracy score. Whereas `Cross-Entropy error` (CSE) calculates how correct or wrong a given prediction is. E.g a prediction that was just barely right will receive a lower score in CSE than in MSE, same case when a prediction was only just incorrect, MSE sees it as entirely wrong whereas CSE still gives points for being almost right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An utter terrible accuracy score of 0.11, considering that infinitely flipping a coin has an accuracy score of 0.5 for each side. this model is worse that a coin flip (not considering a coin has 2 possible outcomes and this model has 10).\n",
    "\n",
    "This is because 1 layer cannot detect enough patterns, or at least not on a high enough level. Adding more layers should fix this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt #2 multiple hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.truncated_normal(shape=[784, 400], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[400]))\n",
    "h1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=[400, 100], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[100]))\n",
    "h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal(shape=[100, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "y = tf.nn.softmax(tf.matmul(h2, W3) + b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set accuracy measurement, batches and  train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "A rounded accuracy score of 0.97, that's an amazing improvement from the original 0.11 accuracy score. And the only thing that was changed was adding another hidden layer. Tt will be difficult to get much more out of this without spending too much effort.\n",
    "\n",
    "Drawback of this current solution is that it  doesnt say how correct it think its classification is. Take for example if we were to feed an alphabetic letter, it would classify the letter to the digit it most resembles. By adding a certainty score we can also ignore certain outcomes that are not certain enough, to root out false classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "[1] Yal, O. G. (2019, September 5). Image Classification in 10 Minutes with MNIST Dataset. Retrieved October 14, 2019, from https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d.\n",
    "\n",
    "[2] Nielsen, & A., M. (unknown date). Neural Networks and Deep Learning. Retrieved September 13, 2019, from http://neuralnetworksanddeeplearning.com/chap1.html.\n",
    "\n",
    "[3] How neural networks work - A simple introduction. (2019, April 4). Retrieved September 13, 2019, from https://www.explainthatstuff.com/introduction-to-neural-networks.html.\n",
    "\n",
    "[4] Ojaswy. (n.d.). Ojaswy/Neural-Networks-Recognizing-hand-written-digits. Retrieved September 12, 2019, from https://github.com/Ojaswy/Neural-Networks-Recognizing-hand-written-digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
